{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Config stuff",
   "id": "21015048f40aff18"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-26T09:47:42.745633Z",
     "start_time": "2024-11-26T09:47:41.483429Z"
    }
   },
   "source": [
    "from xmlrpc.client import DateTime\n",
    "\n",
    "import ConnectionConfig as cc\n",
    "from delta import DeltaTable\n",
    "cc.setupEnvironment()"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Start local cluster",
   "id": "4baf5e0d3af12170"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T09:48:06.527547Z",
     "start_time": "2024-11-26T09:47:46.134786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spark = cc.startLocalCluster(\"FACT_RIDES\")\n",
    "spark.getActiveSession()"
   ],
   "id": "1682df97d406f91b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x29f7fcd0a90>"
      ],
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-5LDFMLTG:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>FACT_RIDES</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Create facts table: rides",
   "id": "b9b9b6d7e21766e7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Read from sources",
   "id": "1380829350c8bdbe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Read from VeloDB database",
   "id": "8275f9036f4aefa4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T10:35:04.110577Z",
     "start_time": "2024-11-26T10:35:03.516191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#EXTRACT\n",
    "\n",
    "cc.set_connectionProfile(\"VeloDB\")\n",
    "\n",
    "# Read rides table from source VeloDB database\n",
    "# Only rows after 2019-01-01 will be read because older rows are corrupt\n",
    "rides_source_df = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", cc.create_jdbc()) \\\n",
    "    .option(\"driver\" , cc.get_Property(\"driver\")) \\\n",
    "    .option(\"dbtable\", \"(select rideid, starttime, endtime, subscriptionid, startlockid, endlockid from rides where starttime > '2019-01-01') as subq\") \\\n",
    "    .option(\"user\", cc.get_Property(\"username\")) \\\n",
    "    .option(\"password\", cc.get_Property(\"password\")) \\\n",
    "    .option(\"partitionColumn\", \"rideid\") \\\n",
    "    .option(\"numPartitions\", 4) \\\n",
    "    .option(\"lowerBound\", 0) \\\n",
    "    .option(\"upperBound\", 4140000) \\\n",
    "    .load()\n",
    "\n",
    "# Next read operation performs a join between the locks and stations source tables. The goal is to retrieve a zipcode for each lockid. This zipcode is used to link the weather dimension with the facts table \n",
    "locks_with_zip = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", cc.create_jdbc()) \\\n",
    "    .option(\"driver\" , cc.get_Property(\"driver\")) \\\n",
    "    .option(\"dbtable\", \"(select l.lockid, s.zipcode from locks l \\\n",
    "    left outer join stations s on l.stationid = s.stationid) as subq\") \\\n",
    "    .option(\"user\", cc.get_Property(\"username\")) \\\n",
    "    .option(\"password\", cc.get_Property(\"password\")) \\\n",
    "    .option(\"partitionColumn\", \"lockid\") \\\n",
    "    .option(\"numPartitions\", 4) \\\n",
    "    .option(\"lowerBound\", 0) \\\n",
    "    .option(\"upperBound\", 8000) \\\n",
    "    .load()\n",
    "\n",
    "locks_with_zip.show(10)"
   ],
   "id": "f78ee4179ebf769b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|lockid|zipcode|\n",
      "+------+-------+\n",
      "|     1|   2000|\n",
      "|     2|   2000|\n",
      "|     3|   2000|\n",
      "|     4|   2000|\n",
      "|     5|   2000|\n",
      "|     6|   2000|\n",
      "|     7|   2000|\n",
      "|     8|   2000|\n",
      "|     9|   2000|\n",
      "|    10|   2000|\n",
      "+------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T10:35:08.611660Z",
     "start_time": "2024-11-26T10:35:07.083603Z"
    }
   },
   "cell_type": "code",
   "source": "rides_source_df.show(10)",
   "id": "136a30e36181e14",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+-------------------+--------------+-----------+---------+\n",
      "|rideid|          starttime|            endtime|subscriptionid|startlockid|endlockid|\n",
      "+------+-------------------+-------------------+--------------+-----------+---------+\n",
      "|    15|2019-09-22 08:46:43|2019-09-22 09:01:36|         13296|       4849|     3188|\n",
      "|    16|2019-09-22 08:19:51|2019-09-22 08:21:55|         45924|       NULL|     NULL|\n",
      "|    17|2019-09-22 08:27:38|2019-09-22 08:30:25|         25722|       2046|     1951|\n",
      "|    18|2019-09-22 08:41:48|2019-09-22 08:46:52|         31000|       1821|     2186|\n",
      "|    19|2019-09-22 08:50:08|2019-09-22 09:09:02|         59732|       6382|     2700|\n",
      "|    20|2019-09-22 08:29:42|2019-09-22 08:31:40|          NULL|       NULL|     NULL|\n",
      "|    21|2019-09-22 08:05:17|2019-09-22 08:14:44|         31055|       1388|     3401|\n",
      "|    22|2019-09-22 08:39:11|2019-09-22 08:44:46|         65164|       2572|       13|\n",
      "|    23|2019-09-22 08:23:27|2019-09-22 08:30:02|         71164|         50|     2067|\n",
      "|    24|2019-09-22 08:20:54|2019-09-22 08:22:47|         68426|       NULL|     NULL|\n",
      "+------+-------------------+-------------------+--------------+-----------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Read from deltatables",
   "id": "918fa361f6468f22"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T09:52:20.358823Z",
     "start_time": "2024-11-26T09:52:17.679593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#EXTRACT\n",
    "# Dimension date\n",
    "dim_date = spark.read.format(\"delta\").load(\"spark-warehouse/dimdate\")\n",
    "\n",
    "# Dimension weather\n",
    "dim_weather = spark.read.format(\"delta\").load(\"spark-warehouse/dimweather\")\n",
    "\n",
    "# Dimension customer\n",
    "dim_customer = spark.read.format(\"delta\").load(\"spark-warehouse/dimuser\")\n",
    "\n",
    "# Dimension lock\n",
    "dim_lock = spark.read.format(\"delta\").load(\"spark-warehouse/dimlock\")\n",
    "\n"
   ],
   "id": "8ab2574fb49e10fa",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Read from weather data source",
   "id": "fe3de972c98c971d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T10:40:23.795627Z",
     "start_time": "2024-11-26T10:40:22.837824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#EXTRACT\n",
    "weather_responses = spark.read.format(\"json\").option(\"multiLine\",True).load(\"weather\")\n",
    "weather_responses.show(10)"
   ],
   "id": "2f2acde511b34f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---+--------------+----------+-------+--------------------+-----+------+--------------------+--------+----------+--------------------+-----------------+-------+\n",
      "|    base|clouds|cod|         coord|        dt|     id|                main| name|  rain|                 sys|timezone|visibility|             weather|             wind|zipCode|\n",
      "+--------+------+---+--------------+----------+-------+--------------------+-----+------+--------------------+--------+----------+--------------------+-----------------+-------+\n",
      "|stations| {100}|200|{44.34, 10.99}|1583593967|3163858|{298.74, 933, 64,...|Zocca|{3.16}|{IT, 2075663, 166...|    7200|     10000|[{overcast clouds...|{349, 1.18, 0.62}|   2000|\n",
      "|stations| {100}|200|{44.34, 10.99}|1583132121|3163858|{298.74, 933, 64,...|Zocca|{3.16}|{IT, 2075663, 166...|    7200|     10000|[{overcast clouds...|{349, 1.18, 0.62}|   2018|\n",
      "|stations| {100}|200|{44.34, 10.99}|1583134645|3163858|{298.74, 933, 64,...|Zocca|{3.16}|{IT, 2075663, 166...|    7200|     10000|[{overcast clouds...|{349, 1.18, 0.62}|   2020|\n",
      "|stations| {100}|200|{44.34, 10.99}|1585973548|3163858|{298.74, 933, 64,...|Zocca|{3.16}|{IT, 2075663, 166...|    7200|     10000|[{overcast clouds...|{349, 1.18, 0.62}|   2030|\n",
      "|stations| {100}|200|{44.34, 10.99}|1569163778|3163858|{298.74, 933, 64,...|Zocca|{3.16}|{IT, 2075663, 166...|    7200|     10000|[{overcast clouds...|{349, 1.18, 0.62}|   2050|\n",
      "|stations| {100}|200|{44.34, 10.99}|1569968446|3163858|{298.74, 933, 64,...|Zocca|{3.16}|{IT, 2075663, 166...|    7200|     10000|[{overcast clouds...|{349, 1.18, 0.62}|   2060|\n",
      "|stations| {100}|200|{44.34, 10.99}|1575264035|3163858|{298.74, 933, 64,...|Zocca|{3.16}|{IT, 2075663, 166...|    7200|     10000|[{overcast clouds...|{349, 1.18, 0.62}|   2100|\n",
      "|stations| {100}|200|{44.34, 10.99}|1619936979|3163858|{298.74, 933, 64,...|Zocca|{3.16}|{IT, 2075663, 166...|    7200|     10000|[{overcast clouds...|{349, 1.18, 0.62}|   2140|\n",
      "|stations| {100}|200|{44.34, 10.99}|1656838375|3163858|{298.74, 933, 64,...|Zocca|{3.16}|{IT, 2075663, 166...|    7200|     10000|[{overcast clouds...|{349, 1.18, 0.62}|   2170|\n",
      "|stations| {100}|200|{44.34, 10.99}|1659778730|3163858|{298.74, 933, 64,...|Zocca|{3.16}|{IT, 2075663, 166...|    7200|     10000|[{overcast clouds...|{349, 1.18, 0.62}|   2600|\n",
      "+--------+------+---+--------------+----------+-------+--------------------+-----+------+--------------------+--------+----------+--------------------+-----------------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create tempviews",
   "id": "22d0cb85fdb74c02"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T10:40:35.638242Z",
     "start_time": "2024-11-26T10:40:35.608132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Rides source table\n",
    "rides_source_df.createOrReplaceTempView(\"ridesSource\")\n",
    "\n",
    "# Table with lockid's and zipcodes\n",
    "locks_with_zip.createOrReplaceTempView(\"locksZip\")\n",
    "\n",
    "# Dimension date\n",
    "dim_date.createOrReplaceTempView(\"dimDate\")\n",
    "\n",
    "# Dimension weather\n",
    "dim_weather.createOrReplaceTempView(\"dimWeather\")\n",
    "\n",
    "# Weather responses\n",
    "weather_responses.createOrReplaceTempView(\"weatherResponses\")\n",
    "\n",
    "# Dimension customer\n",
    "dim_customer.createOrReplaceTempView(\"dimCustomer\")\n",
    "\n",
    "# Dimension lock\n",
    "dim_lock.createOrReplaceTempView(\"dimLock\")"
   ],
   "id": "cee69800b538c0d7",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Add zipcodes to rides table",
   "id": "8b21081cb158aaad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Join ridesSource with locksZip on lockid so we can add the zipcode to the rides table",
   "id": "e10f71814786bcc5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T09:53:02.812472Z",
     "start_time": "2024-11-26T09:52:57.097795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TRANSFORM\n",
    "rides_with_zipcodes = spark.sql(\"select src.rideid, src.starttime, src.endtime, src.subscriptionid, src.startlockid, \\\n",
    "                                 src.endlockid, lz.zipcode as startlockZipcode \\\n",
    "                                 from ridesSource as src \\\n",
    "                                 left outer join locksZip as lz on src.startlockid = lz.lockid\")\n",
    "rides_with_zipcodes.show(10)"
   ],
   "id": "d210b507dace370f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+-------------------+--------------+-----------+---------+----------------+\n",
      "|rideid|          starttime|            endtime|subscriptionid|startlockid|endlockid|startlockZipcode|\n",
      "+------+-------------------+-------------------+--------------+-----------+---------+----------------+\n",
      "|    18|2019-09-22 08:41:48|2019-09-22 08:46:52|         31000|       1821|     2186|            2018|\n",
      "|    23|2019-09-22 08:23:27|2019-09-22 08:30:02|         71164|         50|     2067|            2000|\n",
      "|    15|2019-09-22 08:46:43|2019-09-22 09:01:36|         13296|       4849|     3188|            2140|\n",
      "|    19|2019-09-22 08:50:08|2019-09-22 09:09:02|         59732|       6382|     2700|            2660|\n",
      "|    25|2019-09-22 08:48:14|2019-09-22 08:52:45|           999|        985|     2148|            2018|\n",
      "|    16|2019-09-22 08:19:51|2019-09-22 08:21:55|         45924|       NULL|     NULL|            NULL|\n",
      "|    17|2019-09-22 08:27:38|2019-09-22 08:30:25|         25722|       2046|     1951|            2000|\n",
      "|    20|2019-09-22 08:29:42|2019-09-22 08:31:40|          NULL|       NULL|     NULL|            NULL|\n",
      "|    21|2019-09-22 08:05:17|2019-09-22 08:14:44|         31055|       1388|     3401|            2018|\n",
      "|    22|2019-09-22 08:39:11|2019-09-22 08:44:46|         65164|       2572|       13|            2000|\n",
      "+------+-------------------+-------------------+--------------+-----------+---------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T09:53:24.687841Z",
     "start_time": "2024-11-26T09:53:24.666884Z"
    }
   },
   "cell_type": "code",
   "source": "rides_with_zipcodes.createOrReplaceTempView(\"ridesWithZip\")",
   "id": "e586ec69316a116e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Transform weather responses table",
   "id": "bb87cc70b13038d2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Add weather_ID based on the weather type (condition_id)\n",
    "\n",
    "Condition id:\n",
    "- < 800: All codes with a number smaller than 800 means rain in some form. (=onaangenaam code 2)\n",
    "- = 800: This code means clear sky and sunshine (=aangenaam code 1 if temperature is higher than 15 degrees Celsius)\n",
    "- \\> 800: All other weather conditions (Neutraal code 3)"
   ],
   "id": "c71761d400efc5fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T10:40:42.130170Z",
     "start_time": "2024-11-26T10:40:41.974995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#TRANSFORM\n",
    "short_weather_responses = spark.sql(\"select zipCode as zip_code, dt as timestamp, weather.id[0] as condition_id, main.temp as temperature, \\\n",
    "                                    case \\\n",
    "                                        when condition_id < 800 then 2 \\\n",
    "                                        when condition_id = 800 and main.temp > (273 + 15) then 1 \\\n",
    "                                        when condition_id = 800 and main.temp < (273 + 15) then 3 \\\n",
    "                                        when condition_id > 800 then 3 \\\n",
    "                                    else 4 \\\n",
    "                                    end as weather_ID \\\n",
    "                                    from weatherResponses\")\n",
    "short_weather_responses.show(10)"
   ],
   "id": "3c18954ca1662ff7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+------------+-----------+----------+\n",
      "|zip_code| timestamp|condition_id|temperature|weather_ID|\n",
      "+--------+----------+------------+-----------+----------+\n",
      "|    2000|1583593967|         804|     298.48|         3|\n",
      "|    2018|1583132121|         804|     298.48|         3|\n",
      "|    2020|1583134645|         804|     298.48|         3|\n",
      "|    2030|1585973548|         804|     298.48|         3|\n",
      "|    2050|1569163778|         804|     298.48|         3|\n",
      "|    2060|1569968446|         804|     298.48|         3|\n",
      "|    2100|1575264035|         804|     298.48|         3|\n",
      "|    2140|1619936979|         804|     298.48|         3|\n",
      "|    2170|1656838375|         804|     298.48|         3|\n",
      "|    2600|1659778730|         804|     298.48|         3|\n",
      "+--------+----------+------------+-----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T10:40:45.776536Z",
     "start_time": "2024-11-26T10:40:45.757873Z"
    }
   },
   "cell_type": "code",
   "source": "short_weather_responses.createOrReplaceTempView(\"shortWeatherResponses\")",
   "id": "bd06a92167783835",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Build facts table",
   "id": "c375e6bee2760aa2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T10:40:55.064251Z",
     "start_time": "2024-11-26T10:40:49.019966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#TRANSFORM\n",
    "rides_fact_df = spark.sql(\"select src.rideid as ride_ID, dd.date_SK, \\\n",
    "                          coalesce(dw.weather_SK, 3) as weather_SK, \\\n",
    "                          1 as count_MV, \\\n",
    "                          (unix_timestamp(endtime) - unix_timestamp(starttime)) as rideDuration_MV, \\\n",
    "                          md5(concat(src.rideid, dd.date_SK, coalesce(dw.weather_SK, 3), 1, rideDuration_MV)) as md5 \\\n",
    "                          from ridesWithZip as src \\\n",
    "                          left outer join dimDate as dd \\\n",
    "                          on cast(src.starttime as DATE) = cast(dd.CalendarDate as DATE) \\\n",
    "                          left outer join shortWeatherResponses wr \\\n",
    "                          on src.startlockZipcode = wr.zip_code \\\n",
    "                          and date_format(src.starttime, 'yyyy-MM-dd-HH') = date_format(from_unixtime(wr.timestamp),'yyyy-MM-dd-HH') \\\n",
    "                          left outer join dimWeather dw on dw.weather_id = wr.weather_ID \\\n",
    "                          where src.subscriptionid is not null \")\n",
    "\n",
    "rides_fact_df.show(10)"
   ],
   "id": "629d1cdcbba63806",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----------+--------+---------------+--------------------+\n",
      "|ride_ID|date_SK|weather_SK|count_MV|rideDuration_MV|                 md5|\n",
      "+-------+-------+----------+--------+---------------+--------------------+\n",
      "|     18|     21|         3|       1|            304|8ae4eeec24c367d5d...|\n",
      "|     23|     21|         3|       1|            395|d1a51dbb9eb899c4f...|\n",
      "|     26|     21|         3|       1|            641|0495f90b50d12567e...|\n",
      "|     27|     21|         3|       1|           1176|7d493b85be00b2a6d...|\n",
      "|     34|     21|         3|       1|            677|9e6c18e335cb603d9...|\n",
      "|     36|     21|         3|       1|           1066|3994164be2545f135...|\n",
      "|     42|     21|         3|       1|             25|e90776aa1f7fadaf2...|\n",
      "|     43|     21|         3|       1|            391|8c6a7f5b38fdecf27...|\n",
      "|     45|     21|         3|       1|            269|2297c7674e590f594...|\n",
      "|     50|     21|         3|       1|            314|f4d745d86eefd588c...|\n",
      "+-------+-------+----------+--------+---------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create temview from facts table",
   "id": "2a5d8d8b2b2878a7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T10:41:00.190688Z",
     "start_time": "2024-11-26T10:41:00.171849Z"
    }
   },
   "cell_type": "code",
   "source": "rides_fact_df.createOrReplaceTempView(\"factRides_new\")",
   "id": "35c980efea70ba7c",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Write facts table to delta table: Initial load",
   "id": "3982c905d6e38c4b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T10:41:46.940478Z",
     "start_time": "2024-11-26T10:41:34.856056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LOAD\n",
    "rides_fact_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"factRides\")"
   ],
   "id": "bfc28907c0791b44",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Incremental load",
   "id": "4c7accdf334aa1ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T10:42:16.753169Z",
     "start_time": "2024-11-26T10:41:51.881236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#LOAD\n",
    "dt_factRides = DeltaTable.forPath(spark,\".\\spark-warehouse\\\\factrides\")\n",
    "dt_factRides.toDF().createOrReplaceTempView(\"factRides_current\")\n",
    "\n",
    "result = spark.sql(\"merge into factRides_current as target \\\n",
    "                   using factRides_new as source on target.ride_ID = source.ride_ID \\\n",
    "                   when matched and target.md5 <> source.md5 then update set * \\\n",
    "                   when not matched then insert *\")\n",
    "\n",
    "result.show()"
   ],
   "id": "a9f0e0a4e63a43bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+----------------+-----------------+\n",
      "|num_affected_rows|num_updated_rows|num_deleted_rows|num_inserted_rows|\n",
      "+-----------------+----------------+----------------+-----------------+\n",
      "|                0|               0|               0|                0|\n",
      "+-----------------+----------------+----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T10:51:29.537373Z",
     "start_time": "2024-11-26T10:51:29.297820Z"
    }
   },
   "cell_type": "code",
   "source": "spark.stop()",
   "id": "dfa054e8b32a32a2",
   "outputs": [],
   "execution_count": 52
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
