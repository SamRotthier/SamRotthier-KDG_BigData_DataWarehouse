{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Config stuff",
   "id": "21015048f40aff18"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-03T18:39:09.278286Z",
     "start_time": "2025-01-03T18:39:09.134772Z"
    }
   },
   "source": [
    "import ConnectionConfig as cc\n",
    "from delta import DeltaTable\n",
    "cc.setupEnvironment()"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Start local cluster",
   "id": "4baf5e0d3af12170"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T18:39:30.852974Z",
     "start_time": "2025-01-03T18:39:11.844498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spark = cc.startLocalCluster(\"FACT_RIDES\")\n",
    "spark.getActiveSession()"
   ],
   "id": "1682df97d406f91b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x263c07c1250>"
      ],
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-5LDFMLTG:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>FACT_RIDES</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Create facts table: rides",
   "id": "b9b9b6d7e21766e7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Read from sources",
   "id": "1380829350c8bdbe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Read from VeloDB database",
   "id": "8275f9036f4aefa4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T18:40:33.433335Z",
     "start_time": "2025-01-03T18:40:31.670659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#EXTRACT\n",
    "\n",
    "cc.set_connectionProfile(\"VeloDB\")\n",
    "\n",
    "# Read rides table from source VeloDB database\n",
    "# Only rows after 2019-01-01 will be read because older rows are corrupt\n",
    "rides_source_df = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", cc.create_jdbc()) \\\n",
    "    .option(\"driver\" , cc.get_Property(\"driver\")) \\\n",
    "    .option(\"dbtable\", \"(select rideid, starttime, endtime, subscriptionid, startlockid, endlockid, round(haversine_km(startpoint[0] :: numeric, startpoint[1]:: numeric, endpoint[0]:: numeric, endpoint[1]:: numeric),3) as distance_km_MV from rides where starttime > '2019-01-01') as subq\") \\\n",
    "    .option(\"user\", cc.get_Property(\"username\")) \\\n",
    "    .option(\"password\", cc.get_Property(\"password\")) \\\n",
    "    .option(\"partitionColumn\", \"rideid\") \\\n",
    "    .option(\"numPartitions\", 4) \\\n",
    "    .option(\"lowerBound\", 0) \\\n",
    "    .option(\"upperBound\", 4140000) \\\n",
    "    .load()\n",
    "\n",
    "rides_source_df.show(10)"
   ],
   "id": "f78ee4179ebf769b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Read from deltatables",
   "id": "918fa361f6468f22"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T18:42:34.642554Z",
     "start_time": "2025-01-03T18:42:31.597952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#EXTRACT\n",
    "# Dimension date\n",
    "dim_date = spark.read.format(\"delta\").load(\"spark-warehouse/dimdate\")\n",
    "\n",
    "# Dimension weather\n",
    "dim_weather = spark.read.format(\"delta\").load(\"spark-warehouse/dimweather\")\n",
    "\n",
    "# Dimension customer\n",
    "dim_customer = spark.read.format(\"delta\").load(\"spark-warehouse/dimuser\")\n",
    "\n",
    "# Dimension lock\n",
    "dim_lock = spark.read.format(\"delta\").load(\"spark-warehouse/dimlock\")"
   ],
   "id": "8ab2574fb49e10fa",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Read from weather data source",
   "id": "fe3de972c98c971d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T18:43:11.436841Z",
     "start_time": "2025-01-03T18:43:09.594722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#EXTRACT\n",
    "weather_responses = spark.read.format(\"json\").option(\"multiLine\",True).load(\"weather\")\n",
    "weather_responses.show(10)"
   ],
   "id": "2f2acde511b34f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---+--------------+----------+-------+--------------------+-----+------+--------------------+--------+----------+--------------------+-----------------+-------+\n",
      "|    base|clouds|cod|         coord|        dt|     id|                main| name|  rain|                 sys|timezone|visibility|             weather|             wind|zipCode|\n",
      "+--------+------+---+--------------+----------+-------+--------------------+-----+------+--------------------+--------+----------+--------------------+-----------------+-------+\n",
      "|stations| {100}|200|{44.34, 10.99}|1583593967|3163858|{298.74, 933, 64,...|Zocca|{3.16}|{IT, 2075663, 166...|    7200|     10000|[{overcast clouds...|{349, 1.18, 0.62}|   2000|\n",
      "|stations| {100}|200|{44.34, 10.99}|1583132121|3163858|{298.74, 933, 64,...|Zocca|{3.16}|{IT, 2075663, 166...|    7200|     10000|[{overcast clouds...|{349, 1.18, 0.62}|   2018|\n",
      "|stations| {100}|200|{44.34, 10.99}|1583134645|3163858|{298.74, 933, 64,...|Zocca|{3.16}|{IT, 2075663, 166...|    7200|     10000|[{overcast clouds...|{349, 1.18, 0.62}|   2020|\n",
      "|stations| {100}|200|{44.34, 10.99}|1585973548|3163858|{298.74, 933, 64,...|Zocca|{3.16}|{IT, 2075663, 166...|    7200|     10000|[{overcast clouds...|{349, 1.18, 0.62}|   2030|\n",
      "|stations| {100}|200|{44.34, 10.99}|1569163778|3163858|{298.74, 933, 64,...|Zocca|{3.16}|{IT, 2075663, 166...|    7200|     10000|[{overcast clouds...|{349, 1.18, 0.62}|   2050|\n",
      "|stations| {100}|200|{44.34, 10.99}|1569968446|3163858|{298.74, 933, 64,...|Zocca|{3.16}|{IT, 2075663, 166...|    7200|     10000|[{overcast clouds...|{349, 1.18, 0.62}|   2060|\n",
      "|stations| {100}|200|{44.34, 10.99}|1575264035|3163858|{298.74, 933, 64,...|Zocca|{3.16}|{IT, 2075663, 166...|    7200|     10000|[{overcast clouds...|{349, 1.18, 0.62}|   2100|\n",
      "|stations| {100}|200|{44.34, 10.99}|1619936979|3163858|{298.74, 933, 64,...|Zocca|{3.16}|{IT, 2075663, 166...|    7200|     10000|[{overcast clouds...|{349, 1.18, 0.62}|   2140|\n",
      "|stations| {100}|200|{44.34, 10.99}|1656838375|3163858|{298.74, 933, 64,...|Zocca|{3.16}|{IT, 2075663, 166...|    7200|     10000|[{overcast clouds...|{349, 1.18, 0.62}|   2170|\n",
      "|stations| {100}|200|{44.34, 10.99}|1659778730|3163858|{298.74, 933, 64,...|Zocca|{3.16}|{IT, 2075663, 166...|    7200|     10000|[{overcast clouds...|{349, 1.18, 0.62}|   2600|\n",
      "+--------+------+---+--------------+----------+-------+--------------------+-----+------+--------------------+--------+----------+--------------------+-----------------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create tempviews",
   "id": "22d0cb85fdb74c02"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T18:43:16.486409Z",
     "start_time": "2025-01-03T18:43:16.401361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Rides source table\n",
    "rides_source_df.createOrReplaceTempView(\"ridesSource\")\n",
    "\n",
    "# Dimension date\n",
    "dim_date.createOrReplaceTempView(\"dimDate\")\n",
    "\n",
    "# Dimension weather\n",
    "dim_weather.createOrReplaceTempView(\"dimWeather\")\n",
    "\n",
    "# Weather responses\n",
    "weather_responses.createOrReplaceTempView(\"weatherResponses\")\n",
    "\n",
    "# Dimension customer\n",
    "dim_customer.createOrReplaceTempView(\"dimCustomer\")\n",
    "\n",
    "# Dimension lock\n",
    "dim_lock.createOrReplaceTempView(\"dimLock\")"
   ],
   "id": "cee69800b538c0d7",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Transform weather responses table",
   "id": "bb87cc70b13038d2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Add weather_ID based on the weather type (condition_id)\n",
    "\n",
    "Condition id:\n",
    "- < 800: All codes with a number smaller than 800 means rain in some form. (=onaangenaam code 2)\n",
    "- = 800: This code means clear sky and sunshine (=aangenaam code 1 if temperature is higher than 15 degrees Celsius)\n",
    "- \\> 800: All other weather conditions (Neutraal code 3)"
   ],
   "id": "c71761d400efc5fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T18:43:22.391115Z",
     "start_time": "2025-01-03T18:43:21.406906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#TRANSFORM\n",
    "short_weather_responses = spark.sql(\"select zipCode as zip_code, dt as timestamp, weather.id[0] as condition_id, main.temp as temperature, \\\n",
    "                                    case \\\n",
    "                                        when condition_id < 800 then 2 \\\n",
    "                                        when condition_id = 800 and main.temp > (273 + 15) then 1 \\\n",
    "                                        when condition_id = 800 and main.temp < (273 + 15) then 3 \\\n",
    "                                        when condition_id > 800 then 3 \\\n",
    "                                    else 4 \\\n",
    "                                    end as weather_ID \\\n",
    "                                    from weatherResponses\")\n",
    "short_weather_responses.show(10)"
   ],
   "id": "3c18954ca1662ff7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+------------+-----------+----------+\n",
      "|zip_code| timestamp|condition_id|temperature|weather_ID|\n",
      "+--------+----------+------------+-----------+----------+\n",
      "|    2000|1583593967|         804|     298.48|         3|\n",
      "|    2018|1583132121|         804|     298.48|         3|\n",
      "|    2020|1583134645|         804|     298.48|         3|\n",
      "|    2030|1585973548|         804|     298.48|         3|\n",
      "|    2050|1569163778|         804|     298.48|         3|\n",
      "|    2060|1569968446|         804|     298.48|         3|\n",
      "|    2100|1575264035|         804|     298.48|         3|\n",
      "|    2140|1619936979|         804|     298.48|         3|\n",
      "|    2170|1656838375|         804|     298.48|         3|\n",
      "|    2600|1659778730|         804|     298.48|         3|\n",
      "+--------+----------+------------+-----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T18:43:25.975477Z",
     "start_time": "2025-01-03T18:43:25.953100Z"
    }
   },
   "cell_type": "code",
   "source": "short_weather_responses.createOrReplaceTempView(\"shortWeatherResponses\")",
   "id": "bd06a92167783835",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Build facts table",
   "id": "c375e6bee2760aa2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T18:53:36.605463Z",
     "start_time": "2025-01-03T18:53:14.695751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#TRANSFORM\n",
    "rides_fact_df = spark.sql(\"select src.rideid as ride_ID, dd.date_SK, \\\n",
    "                          coalesce(dw.weather_SK, 3) as weather_SK, \\\n",
    "                          dls.lock_SK as start_lock_SK, dle.lock_SK as end_lock_SK, \\\n",
    "                          1 as count_MV, \\\n",
    "                          (unix_timestamp(endtime) - unix_timestamp(starttime)) as rideDuration_MV, \\\n",
    "                          src.distance_km_MV as distance_km_MV,\\\n",
    "                          md5(concat(src.rideid, dd.date_SK, start_lock_SK, end_lock_SK, coalesce(dw.weather_SK, 3), 1, rideDuration_MV, distance_km_MV)) as md5 \\\n",
    "                          from ridesSource as src \\\n",
    "                          left outer join dimDate as dd \\\n",
    "                          on cast(src.starttime as DATE) = cast(dd.CalendarDate as DATE) \\\n",
    "                          left outer join dimLock dls on src.startlockid = dls.lockid \\\n",
    "                          left outer join dimLock dle on src.endlockid = dle.lockid \\\n",
    "                          left outer join shortWeatherResponses wr on dls.zipcode = string(wr.zip_code) \\\n",
    "                          and date_format(src.starttime, 'yyyy-MM-dd-HH') = date_format(from_unixtime(wr.timestamp),'yyyy-MM-dd-HH') \\\n",
    "                          left outer join dimWeather dw on dw.weather_id = wr.weather_ID \\\n",
    "                          left outer join dimCustomer dc on src.subscriptionid = dc.subscriptionid \\\n",
    "                          where src.subscriptionid is not null and dc.userid is not null\")\n",
    "\n",
    "rides_fact_df.show(10)"
   ],
   "id": "629d1cdcbba63806",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----------+--------------------+--------------------+--------+---------------+--------------------+--------------------+\n",
      "|ride_ID|date_SK|weather_SK|       start_lock_SK|         end_lock_SK|count_MV|rideDuration_MV|      distance_km_MV|                 md5|\n",
      "+-------+-------+----------+--------------------+--------------------+--------+---------------+--------------------+--------------------+\n",
      "|     15|     21|         3|64507040-7b6b-42d...|1f447769-441f-4e8...|       1|            893|3.443000000000000000|2290290ec6874a54b...|\n",
      "|     17|     21|         3|f1ea858c-14ea-4e6...|959ed69c-1e67-40b...|       1|            167|0.699000000000000000|494b0a0f426b5cd20...|\n",
      "|     19|     21|         3|f702d617-2669-457...|12e45297-054d-43c...|       1|           1134|4.884000000000000000|5da055d4ec0db7d91...|\n",
      "|     22|     21|         3|a0d504f4-0da9-49f...|11ce321f-29d9-489...|       1|            335|1.402000000000000000|13f5f3662abd640fd...|\n",
      "|     24|     21|         3|                NULL|                NULL|       1|            113|0.654000000000000000|                NULL|\n",
      "|     25|     21|         3|0a527024-0bd9-40a...|04244331-e7f6-4ae...|       1|            271|1.061000000000000000|6044d80e5cb540bfe...|\n",
      "|     26|     21|         3|3375566d-1cec-428...|50a2ea23-8604-4cf...|       1|            641|2.545000000000000000|a398ad4442ee4a00f...|\n",
      "|     27|     21|         3|8ef1382c-8f75-420...|006c60f6-bea4-4ec...|       1|           1176|5.576000000000000000|4856c4d7179fa180a...|\n",
      "|     28|     21|         3|db1236f7-fd59-4fc...|4aafc616-58e1-435...|       1|              0|0.000000000000000000|c78f985dde56c35d6...|\n",
      "|     29|     21|         3|fa1675d0-e0d2-410...|be9072de-2fe1-4d6...|       1|            194|0.893000000000000000|9d95d36be31638c1e...|\n",
      "+-------+-------+----------+--------------------+--------------------+--------+---------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create temview from facts table",
   "id": "2a5d8d8b2b2878a7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T18:48:43.637487Z",
     "start_time": "2025-01-03T18:48:43.615293Z"
    }
   },
   "cell_type": "code",
   "source": "rides_fact_df.createOrReplaceTempView(\"factRides_new\")",
   "id": "35c980efea70ba7c",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Write facts table to delta table: Initial load",
   "id": "3982c905d6e38c4b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T18:49:33.005597Z",
     "start_time": "2025-01-03T18:48:46.747653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LOAD\n",
    "rides_fact_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"factRides\")"
   ],
   "id": "bfc28907c0791b44",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Incremental load",
   "id": "4c7accdf334aa1ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T18:30:34.803897Z",
     "start_time": "2024-12-26T18:29:59.355289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#LOAD\n",
    "dt_factRides = DeltaTable.forPath(spark,\".\\spark-warehouse\\\\factrides\")\n",
    "dt_factRides.toDF().createOrReplaceTempView(\"factRides_current\")\n",
    "\n",
    "result = spark.sql(\"merge into factRides_current as target \\\n",
    "                   using factRides_new as source on target.ride_ID = source.ride_ID \\\n",
    "                   when matched and (target.md5 <> source.md5) then update set * \\\n",
    "                   when not matched then insert *\")\n",
    "\n",
    "result.show()"
   ],
   "id": "a9f0e0a4e63a43bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+----------------+-----------------+\n",
      "|num_affected_rows|num_updated_rows|num_deleted_rows|num_inserted_rows|\n",
      "+-----------------+----------------+----------------+-----------------+\n",
      "|                0|               0|               0|                0|\n",
      "+-----------------+----------------+----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T16:31:48.277991Z",
     "start_time": "2025-01-03T16:31:46.123633Z"
    }
   },
   "cell_type": "code",
   "source": "spark.stop()",
   "id": "dfa054e8b32a32a2",
   "outputs": [
    {
     "ename": "ConnectionRefusedError",
     "evalue": "[WinError 10061] Kan geen verbinding maken omdat de doelcomputer de verbinding actief heeft geweigerd",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mConnectionRefusedError\u001B[0m                    Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mspark\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\datawarehouse\\Lib\\site-packages\\pyspark\\sql\\session.py:1796\u001B[0m, in \u001B[0;36mSparkSession.stop\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1782\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1783\u001B[0m \u001B[38;5;124;03mStop the underlying :class:`SparkContext`.\u001B[39;00m\n\u001B[0;32m   1784\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1792\u001B[0m \u001B[38;5;124;03m>>> spark.stop()  # doctest: +SKIP\u001B[39;00m\n\u001B[0;32m   1793\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1794\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcontext\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SQLContext\n\u001B[1;32m-> 1796\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1797\u001B[0m \u001B[38;5;66;03m# We should clean the default session up. See SPARK-23228.\u001B[39;00m\n\u001B[0;32m   1798\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jvm \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\datawarehouse\\Lib\\site-packages\\pyspark\\context.py:654\u001B[0m, in \u001B[0;36mSparkContext.stop\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    652\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_jsc\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    653\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 654\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jsc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    655\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m Py4JError:\n\u001B[0;32m    656\u001B[0m         \u001B[38;5;66;03m# Case: SPARK-18523\u001B[39;00m\n\u001B[0;32m    657\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    658\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnable to cleanly shutdown Spark JVM process.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    659\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m It is possible that the process has crashed,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    660\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m been killed or may also be in a zombie state.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    661\u001B[0m             \u001B[38;5;167;01mRuntimeWarning\u001B[39;00m,\n\u001B[0;32m    662\u001B[0m         )\n",
      "File \u001B[1;32m~\\PycharmProjects\\datawarehouse\\Lib\\site-packages\\py4j\\java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m   1314\u001B[0m args_command, temp_args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_args(\u001B[38;5;241m*\u001B[39margs)\n\u001B[0;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[0;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[0;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[0;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m-> 1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_command\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcommand\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m get_return_value(\n\u001B[0;32m   1323\u001B[0m     answer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname)\n\u001B[0;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
      "File \u001B[1;32m~\\PycharmProjects\\datawarehouse\\Lib\\site-packages\\py4j\\java_gateway.py:1036\u001B[0m, in \u001B[0;36mGatewayClient.send_command\u001B[1;34m(self, command, retry, binary)\u001B[0m\n\u001B[0;32m   1015\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msend_command\u001B[39m(\u001B[38;5;28mself\u001B[39m, command, retry\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, binary\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m   1016\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Sends a command to the JVM. This method is not intended to be\u001B[39;00m\n\u001B[0;32m   1017\u001B[0m \u001B[38;5;124;03m       called directly by Py4J users. It is usually called by\u001B[39;00m\n\u001B[0;32m   1018\u001B[0m \u001B[38;5;124;03m       :class:`JavaMember` instances.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1034\u001B[0m \u001B[38;5;124;03m     if `binary` is `True`.\u001B[39;00m\n\u001B[0;32m   1035\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1036\u001B[0m     connection \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_connection\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1037\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1038\u001B[0m         response \u001B[38;5;241m=\u001B[39m connection\u001B[38;5;241m.\u001B[39msend_command(command)\n",
      "File \u001B[1;32m~\\PycharmProjects\\datawarehouse\\Lib\\site-packages\\py4j\\clientserver.py:284\u001B[0m, in \u001B[0;36mJavaClient._get_connection\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    281\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m    283\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m connection \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m connection\u001B[38;5;241m.\u001B[39msocket \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 284\u001B[0m     connection \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_new_connection\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    285\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m connection\n",
      "File \u001B[1;32m~\\PycharmProjects\\datawarehouse\\Lib\\site-packages\\py4j\\clientserver.py:291\u001B[0m, in \u001B[0;36mJavaClient._create_new_connection\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    287\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_create_new_connection\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    288\u001B[0m     connection \u001B[38;5;241m=\u001B[39m ClientServerConnection(\n\u001B[0;32m    289\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mjava_parameters, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpython_parameters,\n\u001B[0;32m    290\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_property, \u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m--> 291\u001B[0m     \u001B[43mconnection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect_to_java_server\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    292\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mset_thread_connection(connection)\n\u001B[0;32m    293\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m connection\n",
      "File \u001B[1;32m~\\PycharmProjects\\datawarehouse\\Lib\\site-packages\\py4j\\clientserver.py:438\u001B[0m, in \u001B[0;36mClientServerConnection.connect_to_java_server\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    435\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mssl_context:\n\u001B[0;32m    436\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msocket \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mssl_context\u001B[38;5;241m.\u001B[39mwrap_socket(\n\u001B[0;32m    437\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msocket, server_hostname\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mjava_address)\n\u001B[1;32m--> 438\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msocket\u001B[38;5;241m.\u001B[39mconnect((\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mjava_address, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mjava_port))\n\u001B[0;32m    439\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msocket\u001B[38;5;241m.\u001B[39mmakefile(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    440\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_connected \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[1;31mConnectionRefusedError\u001B[0m: [WinError 10061] Kan geen verbinding maken omdat de doelcomputer de verbinding actief heeft geweigerd"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
