{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Config stuff",
   "id": "73093dc844677cfe"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-18T19:22:35.545094Z",
     "start_time": "2024-11-18T19:22:35.395120Z"
    }
   },
   "source": [
    "import ConnectionConfig as cc\n",
    "cc.setupEnvironment()"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Start local cluster",
   "id": "ab743311b9e6c6b4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T19:22:59.633990Z",
     "start_time": "2024-11-18T19:22:41.196039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spark = cc.startLocalCluster(\"DIM_DATE\",4)\n",
    "spark.getActiveSession()"
   ],
   "id": "819ae45fa199e238",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1dae6e30710>"
      ],
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-5LDFMLTG:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>DIM_DATE</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Create date dimension",
   "id": "84d21e194747f55e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 1: Generate rows for a sequence of dates",
   "id": "aee29f4711967116"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Find the oldest date and the newest date in the rides table. I will do this by querying the rides table in the VeloDB database with a query console.",
   "id": "acdca7f1cbd5f55e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T19:23:16.470763Z",
     "start_time": "2024-11-18T19:23:11.592066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Extract\n",
    "startDate = '2019-09-01'\n",
    "endDate = '2023-09-17'\n",
    "\n",
    "df_dates = spark.sql(f\"select explode(sequence(to_date('{startDate}'), to_date('{endDate}'), interval 1 day)) as calendarDate, monotonically_increasing_id() as date_SK \")\n",
    "\n",
    "df_dates.show(10)"
   ],
   "id": "7912ba4b79db9689",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+\n",
      "|calendarDate|date_SK|\n",
      "+------------+-------+\n",
      "|  2019-09-01|      0|\n",
      "|  2019-09-02|      1|\n",
      "|  2019-09-03|      2|\n",
      "|  2019-09-04|      3|\n",
      "|  2019-09-05|      4|\n",
      "|  2019-09-06|      5|\n",
      "|  2019-09-07|      6|\n",
      "|  2019-09-08|      7|\n",
      "|  2019-09-09|      8|\n",
      "|  2019-09-10|      9|\n",
      "+------------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 2: Create all dimension fields",
   "id": "be2a1b07ffb18554"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T19:23:48.338296Z",
     "start_time": "2024-11-18T19:23:47.419273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#TRANSFORM\n",
    "df_dates.createOrReplaceTempView('neededDates')\n",
    "\n",
    "dimDate = spark.sql(\"select date_SK, \\\n",
    "  year(calendarDate) * 10000 + month(calendarDate) * 100 + day(calendarDate) as dateInt, \\\n",
    "  CalendarDate, \\\n",
    "  year(calendarDate) AS CalendarYear, \\\n",
    "  date_format(calendarDate, 'MMMM') as CalendarMonth, \\\n",
    "  month(calendarDate) as MonthOfYear, \\\n",
    "  date_format(calendarDate, 'EEEE') as CalendarDay, \\\n",
    "  dayofweek(calendarDate) AS DayOfWeek, \\\n",
    "  weekday(calendarDate) + 1 as DayOfWeekStartMonday, \\\n",
    "  case \\\n",
    "    when weekday(calendarDate) < 5 then 'Y' \\\n",
    "    else 'N' \\\n",
    "  end as IsWeekDay, \\\n",
    "  dayofmonth(calendarDate) as DayOfMonth, \\\n",
    "  case \\\n",
    "    when calendarDate = last_day(calendarDate) then 'Y' \\\n",
    "    else 'N' \\\n",
    "  end as IsLastDayOfMonth, \\\n",
    "  dayofyear(calendarDate) as DayOfYear, \\\n",
    "  weekofyear(calendarDate) as WeekOfYearIso, \\\n",
    "  quarter(calendarDate) as QuarterOfYear \\\n",
    "from  \\\n",
    "  neededDates \\\n",
    "order by \\\n",
    "  calendarDate\")\n",
    "\n",
    "dimDate.show()"
   ],
   "id": "586df3599a2a690e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------------+------------+-------------+-----------+-----------+---------+--------------------+---------+----------+----------------+---------+-------------+-------------+\n",
      "|date_SK| dateInt|CalendarDate|CalendarYear|CalendarMonth|MonthOfYear|CalendarDay|DayOfWeek|DayOfWeekStartMonday|IsWeekDay|DayOfMonth|IsLastDayOfMonth|DayOfYear|WeekOfYearIso|QuarterOfYear|\n",
      "+-------+--------+------------+------------+-------------+-----------+-----------+---------+--------------------+---------+----------+----------------+---------+-------------+-------------+\n",
      "|      0|20190901|  2019-09-01|        2019|    September|          9|     Sunday|        1|                   7|        N|         1|               N|      244|           35|            3|\n",
      "|      1|20190902|  2019-09-02|        2019|    September|          9|     Monday|        2|                   1|        Y|         2|               N|      245|           36|            3|\n",
      "|      2|20190903|  2019-09-03|        2019|    September|          9|    Tuesday|        3|                   2|        Y|         3|               N|      246|           36|            3|\n",
      "|      3|20190904|  2019-09-04|        2019|    September|          9|  Wednesday|        4|                   3|        Y|         4|               N|      247|           36|            3|\n",
      "|      4|20190905|  2019-09-05|        2019|    September|          9|   Thursday|        5|                   4|        Y|         5|               N|      248|           36|            3|\n",
      "|      5|20190906|  2019-09-06|        2019|    September|          9|     Friday|        6|                   5|        Y|         6|               N|      249|           36|            3|\n",
      "|      6|20190907|  2019-09-07|        2019|    September|          9|   Saturday|        7|                   6|        N|         7|               N|      250|           36|            3|\n",
      "|      7|20190908|  2019-09-08|        2019|    September|          9|     Sunday|        1|                   7|        N|         8|               N|      251|           36|            3|\n",
      "|      8|20190909|  2019-09-09|        2019|    September|          9|     Monday|        2|                   1|        Y|         9|               N|      252|           37|            3|\n",
      "|      9|20190910|  2019-09-10|        2019|    September|          9|    Tuesday|        3|                   2|        Y|        10|               N|      253|           37|            3|\n",
      "|     10|20190911|  2019-09-11|        2019|    September|          9|  Wednesday|        4|                   3|        Y|        11|               N|      254|           37|            3|\n",
      "|     11|20190912|  2019-09-12|        2019|    September|          9|   Thursday|        5|                   4|        Y|        12|               N|      255|           37|            3|\n",
      "|     12|20190913|  2019-09-13|        2019|    September|          9|     Friday|        6|                   5|        Y|        13|               N|      256|           37|            3|\n",
      "|     13|20190914|  2019-09-14|        2019|    September|          9|   Saturday|        7|                   6|        N|        14|               N|      257|           37|            3|\n",
      "|     14|20190915|  2019-09-15|        2019|    September|          9|     Sunday|        1|                   7|        N|        15|               N|      258|           37|            3|\n",
      "|     15|20190916|  2019-09-16|        2019|    September|          9|     Monday|        2|                   1|        Y|        16|               N|      259|           38|            3|\n",
      "|     16|20190917|  2019-09-17|        2019|    September|          9|    Tuesday|        3|                   2|        Y|        17|               N|      260|           38|            3|\n",
      "|     17|20190918|  2019-09-18|        2019|    September|          9|  Wednesday|        4|                   3|        Y|        18|               N|      261|           38|            3|\n",
      "|     18|20190919|  2019-09-19|        2019|    September|          9|   Thursday|        5|                   4|        Y|        19|               N|      262|           38|            3|\n",
      "|     19|20190920|  2019-09-20|        2019|    September|          9|     Friday|        6|                   5|        Y|        20|               N|      263|           38|            3|\n",
      "+-------+--------+------------+------------+-------------+-----------+-----------+---------+--------------------+---------+----------+----------------+---------+-------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 3: Save dimension to deltatable",
   "id": "9da55793f892b431"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T19:24:25.377431Z",
     "start_time": "2024-11-18T19:24:18.125356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#LOAD\n",
    "dimDate.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"dimDate\")"
   ],
   "id": "d1b48d1f5b79f8fb",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T19:24:36.962231Z",
     "start_time": "2024-11-18T19:24:36.820794Z"
    }
   },
   "cell_type": "code",
   "source": "spark.stop()",
   "id": "2a99d12d60ebe48b",
   "outputs": [],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
